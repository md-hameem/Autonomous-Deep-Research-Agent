<div align="center">

# ğŸ”¬ Autonomous Deep Research Agent

### Production-Grade Multi-Agent Research System

[![Python 3.11+](https://img.shields.io/badge/Python-3.11+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![LangGraph](https://img.shields.io/badge/LangGraph-0.2+-00ADD8?style=for-the-badge&logo=chainlink&logoColor=white)](https://langchain-ai.github.io/langgraph/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.30+-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)](https://streamlit.io)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](https://opensource.org/licenses/MIT)

*An AI-powered research assistant that autonomously investigates any topic using specialized agents, parallel web searches, and quality-controlled report generation.*

[Features](#-features) â€¢ [Quick Start](#-quick-start) â€¢ [Architecture](#-architecture) â€¢ [Usage](#-usage) â€¢ [API Reference](#-api-reference)

</div>

---

## âœ¨ Features

<table>
<tr>
<td width="50%">

### ğŸ¤– Multi-Agent Architecture
Four specialized AI agents work together:
- **Planner** â€” Creates targeted search strategies
- **Researcher** â€” Executes parallel web searches
- **Critic** â€” Evaluates quality & completeness
- **Writer** â€” Generates structured reports

</td>
<td width="50%">

### âš¡ High Performance
- **Parallel Execution** â€” 3-5x faster research
- **Smart Caching** â€” SQLite-based result caching
- **Async I/O** â€” Non-blocking operations
- **Rate Limiting** â€” Respects API limits

</td>
</tr>
<tr>
<td width="50%">

### ğŸ” Advanced Research
- **Multi-Provider Search** â€” Tavily + Wikipedia + Serper
- **Quality Scoring** â€” 1-10 relevance ratings
- **Fact Checking** â€” Cross-reference validation
- **Iterative Refinement** â€” Auto-improves weak results

</td>
<td width="50%">

### ğŸ¨ Modern Interface
- **Streamlit Web UI** â€” Beautiful dark theme
- **Real-time Streaming** â€” Live progress updates
- **CLI Support** â€” Full command-line interface
- **REST API** â€” FastAPI with WebSocket

</td>
</tr>
</table>

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11 or higher
- [Tavily API Key](https://tavily.com) (free tier available)
- [Anthropic](https://console.anthropic.com) or [OpenAI](https://platform.openai.com) API key

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/autonomous-research-agent.git
cd autonomous-research-agent

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure API keys
cp .env.example .env
# Edit .env with your API keys
```

### Run the Application

<table>
<tr>
<td>

**ğŸ¨ Web Interface**
```bash
streamlit run app.py
```
Opens at `http://localhost:8501`

</td>
<td>

**ğŸ’» Command Line**
```bash
python main.py "Your research topic"
```

</td>
<td>

**ğŸŒ API Server**
```bash
uvicorn api.main:app --reload
```
Opens at `http://localhost:8000`

</td>
</tr>
</table>

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ğŸ¯ WORKFLOW ORCHESTRATOR                      â”‚
â”‚                    (LangGraph State Machine)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                           â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“‹ PLANNER   â”‚           â”‚ ğŸ” RESEARCHER â”‚           â”‚  ğŸ”¬ CRITIC    â”‚
â”‚               â”‚           â”‚               â”‚           â”‚               â”‚
â”‚ â€¢ Analyze     â”‚     â”Œâ”€â”€â”€â”€â–¶â”‚ â€¢ Parallel    â”‚           â”‚ â€¢ Score       â”‚
â”‚   topic       â”‚     â”‚     â”‚   search      â”‚           â”‚   quality     â”‚
â”‚ â€¢ Generate    â”‚â”€â”€â”€â”€â”€â”˜     â”‚ â€¢ Multi-      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ â€¢ Check       â”‚
â”‚   queries     â”‚           â”‚   provider    â”‚           â”‚   coverage    â”‚
â”‚ â€¢ Strategy    â”‚           â”‚ â€¢ Rate &      â”‚           â”‚ â€¢ Suggest     â”‚
â”‚   planning    â”‚           â”‚   cache       â”‚           â”‚   refinements â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                â”‚
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
                            â”‚  ğŸ“ WRITER    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚               â”‚
                            â”‚ â€¢ Structure   â”‚
                            â”‚   report      â”‚
                            â”‚ â€¢ Citations   â”‚
                            â”‚ â€¢ Formatting  â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Workflow

1. **Planning** â†’ Planner breaks topic into 3-5 targeted search queries
2. **Research** â†’ Researcher executes queries in parallel via Tavily + Wikipedia
3. **Evaluation** â†’ Critic scores quality (completeness, diversity, consistency)
4. **Refinement** â†’ If score < 7/10, loops back with improvement suggestions
5. **Writing** â†’ Writer compiles sources into structured markdown report

---

## ğŸ“ Project Structure

```
autonomous-research-agent/
â”‚
â”œâ”€â”€ ğŸ¨ app.py                 # Streamlit Web UI
â”œâ”€â”€ ğŸ’» main.py                # CLI Entry Point
â”œâ”€â”€ ğŸ“¦ pyproject.toml         # Project configuration
â”‚
â”œâ”€â”€ src/                      # Core Package
â”‚   â”œâ”€â”€ config.py             # Configuration management
â”‚   â”œâ”€â”€ state.py              # State definitions
â”‚   â”œâ”€â”€ graph.py              # LangGraph workflow
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/               # Specialized Agents
â”‚   â”‚   â”œâ”€â”€ base.py           # Base agent class
â”‚   â”‚   â”œâ”€â”€ planner.py        # Research planning
â”‚   â”‚   â”œâ”€â”€ researcher.py     # Parallel search
â”‚   â”‚   â”œâ”€â”€ critic.py         # Quality evaluation
â”‚   â”‚   â””â”€â”€ writer.py         # Report generation
â”‚   â”‚
â”‚   â””â”€â”€ tools/                # Utilities
â”‚       â”œâ”€â”€ search.py         # Search providers
â”‚       â””â”€â”€ cache.py          # SQLite caching
â”‚
â”œâ”€â”€ api/                      # REST API
â”‚   â””â”€â”€ main.py               # FastAPI + WebSocket
â”‚
â”œâ”€â”€ tests/                    # Test Suite
â”œâ”€â”€ reports/                  # Generated Reports
â””â”€â”€ data/                     # Cache Storage
```

---

## ğŸ’» Usage

### Web Interface

The Streamlit UI provides the most user-friendly experience:

```bash
streamlit run app.py
```

**Features:**
- ğŸŒ™ Modern dark theme with glassmorphism
- ğŸ“Š Real-time quality metrics
- ğŸ“‹ Live agent activity log
- ğŸ“¥ One-click report download

### Command Line

```bash
# Basic usage
python main.py "Impact of quantum computing on cryptography"

# With options
python main.py --output ./my_reports --max-revisions 3 "AI in healthcare"
```

**Options:**
| Flag | Description | Default |
|------|-------------|---------|
| `--output, -o` | Output directory | `reports/` |
| `--max-revisions, -r` | Max refinement loops | `2` |

### Programmatic API

```python
from src.graph import run_research

# Run research
result = run_research("Climate change mitigation strategies")

# Access results
print(result["final_report"])
print(f"Quality: {result['quality_report']['overall_score']}/10")
print(f"Sources: {len(result['sources'])}")
```

---

## ğŸŒ API Reference

### REST Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/research/start` | Start new research session |
| `GET` | `/api/research/{id}` | Get session status |
| `POST` | `/api/research/{id}/approve` | Approve research plan |
| `GET` | `/api/research/{id}/report` | Get final report |

### WebSocket

```javascript
const ws = new WebSocket('ws://localhost:8000/ws/research/{session_id}');

ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  // Types: 'message', 'status', 'plan', 'quality', 'complete'
  console.log(data.type, data.content);
};
```

---

## âš™ï¸ Configuration

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `TAVILY_API_KEY` | Tavily search API | âœ… |
| `ANTHROPIC_API_KEY` | Claude API key | One of these |
| `OPENAI_API_KEY` | OpenAI API key | required |
| `LLM_PROVIDER` | `anthropic` or `openai` | Default: `anthropic` |
| `SERPER_API_KEY` | Google Search (optional) | âŒ |

### Advanced Configuration

```python
from src.config import get_config

config = get_config()

# Search settings
config.search.max_results_per_query = 10
config.search.max_parallel_searches = 8

# Quality thresholds
config.quality.min_quality_score = 8.0
config.quality.max_refinement_iterations = 3

# Cache settings
config.cache.ttl_hours = 48
```

---

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=src --cov-report=html
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

<div align="center">

**Built with â¤ï¸ using [LangGraph](https://langchain-ai.github.io/langgraph/), [Streamlit](https://streamlit.io), and [Tavily](https://tavily.com)**

â­ Star this repo if you find it useful!

</div>
